{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae72c8c-112e-40d2-9298-52722abf7aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "# Silence SettingWithCopyWarning for categorical assignments\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "# --- Define File Names (Assuming these files are in the same directory) ---\n",
    "FILE_DEMO = 'df_final_demo.txt'\n",
    "FILE_WEB_1 = 'df_final_web_data_pt_1.txt'\n",
    "FILE_WEB_2 = 'df_final_web_data_pt_2.txt'\n",
    "FILE_EXPERIMENT = 'df_final_experiment_clients.txt'\n",
    "\n",
    "# --- 1. Data Loading and Merging (Task 1: Data Preparation) ---\n",
    "def load_and_merge_data(demo_file, web_1_file, web_2_file, experiment_file):\n",
    "    \"\"\"Loads and merges all required datasets.\"\"\"\n",
    "    print(\"--- TASK 1: DATA LOADING AND MERGING ---\")\n",
    "    try:\n",
    "        # Load datasets (using read_csv because your .txt files are CSV-formatted)\n",
    "        df_demo = pd.read_csv(demo_file)\n",
    "        df_web_1 = pd.read_csv(web_1_file)\n",
    "        df_web_2 = pd.read_csv(web_2_file)\n",
    "        df_experiment = pd.read_csv(experiment_file)\n",
    "\n",
    "        df_web = pd.concat([df_web_1, df_web_2], ignore_index=True)\n",
    "\n",
    "        # Standardize client ID column name\n",
    "        for df_ in [df_experiment, df_demo, df_web]:\n",
    "            if 'client_id' in df_.columns:\n",
    "                df_.rename(columns={'client_id': 'Client_ID'}, inplace=True)\n",
    "        \n",
    "        # Merge all data\n",
    "        df_merged = df_experiment.merge(df_demo, on='Client_ID', how='left')\n",
    "        df_merged = df_merged.merge(df_web, on='Client_ID', how='left')\n",
    "        print(\"All datasets merged successfully.\")\n",
    "        return df_merged\n",
    "    except Exception as e:\n",
    "        print(f\"Error during loading/merging: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- 1. EDA & Data Cleaning (Task 1: Data Preparation) ---\n",
    "def perform_eda_and_cleaning(df):\n",
    "    \"\"\"Performs initial EDA and cleaning steps.\"\"\"\n",
    "    if df is None: return None\n",
    "    \n",
    "    print(\"\\n--- TASK 1: EDA AND DATA CLEANING ---\")\n",
    "\n",
    "    # Drop duplicates\n",
    "    initial_rows = len(df)\n",
    "    df.drop_duplicates(subset=['Client_ID', 'date_time', 'process_step'], keep='first', inplace=True)\n",
    "\n",
    "    # Convert date_time and create Date column\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "    df['Date'] = df['date_time'].dt.date\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    # Create 'TestGroup' column\n",
    "    df['TestGroup'] = np.where(df['Variation'] == 'Control', 'Control', 'Test')\n",
    "    \n",
    "    print(f\"Total rows before cleaning: {initial_rows}\")\n",
    "    print(f\"Total rows after cleaning: {len(df)}\")\n",
    "    print(f\"Total unique clients after cleaning: {df['Client_ID'].nunique()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# --- 2. Client Behavior Analysis (Task 2: Analysis) ---\n",
    "def analyze_client_behavior(df):\n",
    "    \"\"\"Answers questions about client demographics and overall funnel performance.\"\"\"\n",
    "    if df is None: return None\n",
    "    \n",
    "    print(\"\\n--- TASK 2: CLIENT BEHAVIOR ANALYSIS ---\")\n",
    "    \n",
    "    # Filter clients with complete demographic data and create a copy\n",
    "    df_unique_clients = df.drop_duplicates(subset=['Client_ID'])\n",
    "    df_analysis_clients = df_unique_clients[df_unique_clients['clnt_age'].notnull()].copy() \n",
    "    total_clients = df_analysis_clients['Client_ID'].nunique()\n",
    "\n",
    "    # --- 3.1.1 Gender Analysis (Uses 'gendr') ---\n",
    "    gender_analysis = df_analysis_clients.groupby('gendr')['Client_ID'].count().sort_values(ascending=False)\n",
    "    gender_pct = (gender_analysis / total_clients * 100).round(2) \n",
    "    print(\"\\n3.1.1 Primary Clients by Gender:\")\n",
    "    print(gender_pct.to_frame(name='Client Pct (%)').to_string()) \n",
    "\n",
    "    # --- 3.1.2 Age Group Analysis (Uses 'clnt_age') ---\n",
    "    age_bins = [18, 30, 45, 60, 100]\n",
    "    age_labels = ['18-29 (Young)', '30-44 (Middle)', '45-59 (Senior)', '60+ (Retired)']\n",
    "    df_analysis_clients['Age_Group'] = pd.cut(df_analysis_clients['clnt_age'], bins=age_bins, labels=age_labels, right=False, include_lowest=True)\n",
    "    \n",
    "    # Corrected for FutureWarning: Added observed=True\n",
    "    age_analysis = df_analysis_clients.groupby('Age_Group', observed=True)['Client_ID'].count()\n",
    "    age_pct = (age_analysis / total_clients * 100).round(2)\n",
    "    print(\"\\n3.1.2 Primary Clients by Age Group:\")\n",
    "    print(age_pct.to_frame(name='Client Pct (%)').to_string())\n",
    "\n",
    "    # --- 3.2.1 Tenure Group Analysis (Uses 'clnt_tenure_yr') ---\n",
    "    tenure_bins = [0, 5, 10, 20, 50]\n",
    "    tenure_labels = ['<5 (New)', '5-9 (Mid-Term)', '10-19 (Long-Term)', '20+ (Veteran)']\n",
    "    df_analysis_clients['Tenure_Group'] = pd.cut(df_analysis_clients['clnt_tenure_yr'], bins=tenure_bins, labels=tenure_labels, right=False, include_lowest=True)\n",
    "    \n",
    "    # Corrected for FutureWarning: Added observed=True\n",
    "    tenure_analysis = df_analysis_clients.groupby('Tenure_Group', observed=True)['Client_ID'].count()\n",
    "    \n",
    "    # Corrected percentage calculation \n",
    "    tenure_pct = tenure_analysis.div(total_clients).mul(100).round(2)\n",
    "    \n",
    "    print(\"\\n3.2.1 Primary Clients by Tenure Group (Years Active):\")\n",
    "    print(tenure_pct.to_frame(name='Client Pct (%)').to_string())\n",
    "    \n",
    "    # --- 3.3.1 Overall Funnel Performance (Conversion Rate) ---\n",
    "    print(\"\\n3.3.1 Overall Process Funnel Analysis:\")\n",
    "    \n",
    "    process_steps = ['start', 'step_1', 'step_2', 'step_3', 'confirm']\n",
    "    step_activity = {step: df[df['process_step'] == step]['Client_ID'].nunique() for step in process_steps}\n",
    "    step_activity_series = pd.Series(step_activity).sort_index()\n",
    "\n",
    "    start_clients = step_activity.get('start', 0)\n",
    "    confirm_clients = step_activity.get('confirm', 0)\n",
    "    \n",
    "    # CRITICAL FIX for AttributeError/NameError: Use the built-in round() function and proper structure\n",
    "    if start_clients > 0:\n",
    "        completion_rate = round((confirm_clients / start_clients * 100), 2)\n",
    "    else:\n",
    "        completion_rate = 0\n",
    "\n",
    "    print(\"Clients reaching each step of the process:\")\n",
    "    print(step_activity_series.to_frame(name='Unique Clients').to_string())\n",
    "    print(f\"\\nOverall Process Completion Rate (Confirm/Start): {completion_rate}%\")\n",
    "    \n",
    "\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "if __name__ == '__main__':\n",
    "    df_merged = load_and_merge_data(FILE_DEMO, FILE_WEB_1, FILE_WEB_2, FILE_EXPERIMENT)\n",
    "    \n",
    "if df_merged is not None:\n",
    "    df_cleaned = perform_eda_and_cleaning(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594eaec1-28c1-477e-b98d-94a7fb6dd146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "# Silence SettingWithCopyWarning for categorical assignments\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "# --- Define File Names (Assuming these files are in the same directory) ---\n",
    "FILE_DEMO = 'df_final_demo.txt'\n",
    "FILE_WEB_1 = 'df_final_web_data_pt_1.txt'\n",
    "FILE_WEB_2 = 'df_final_web_data_pt_2.txt'\n",
    "FILE_EXPERIMENT = 'df_final_experiment_clients.txt'\n",
    "\n",
    "# --- 1. Data Loading and Merging (Task 1: Data Preparation) ---\n",
    "def load_and_merge_data(demo_file, web_1_file, web_2_file, experiment_file):\n",
    "    \"\"\"Loads and merges all required datasets.\"\"\"\n",
    "    print(\"--- TASK 1: DATA LOADING AND MERGING ---\")\n",
    "    try:\n",
    "        # Load datasets (using read_csv because your .txt files are CSV-formatted)\n",
    "        df_demo = pd.read_csv(demo_file)\n",
    "        df_web_1 = pd.read_csv(web_1_file)\n",
    "        df_web_2 = pd.read_csv(web_2_file)\n",
    "        df_experiment = pd.read_csv(experiment_file)\n",
    "\n",
    "        df_web = pd.concat([df_web_1, df_web_2], ignore_index=True)\n",
    "\n",
    "        # Standardize client ID column name\n",
    "        for df_ in [df_experiment, df_demo, df_web]:\n",
    "            if 'client_id' in df_.columns:\n",
    "                df_.rename(columns={'client_id': 'Client_ID'}, inplace=True)\n",
    "        \n",
    "        # Merge all data\n",
    "        df_merged = df_experiment.merge(df_demo, on='Client_ID', how='left')\n",
    "        df_merged = df_merged.merge(df_web, on='Client_ID', how='left')\n",
    "        print(\"All datasets merged successfully.\")\n",
    "        return df_merged\n",
    "    except Exception as e:\n",
    "        print(f\"Error during loading/merging: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- 1. EDA & Data Cleaning (Task 1: Data Preparation) ---\n",
    "def perform_eda_and_cleaning(df):\n",
    "    \"\"\"Performs initial EDA and cleaning steps.\"\"\"\n",
    "    if df is None: return None\n",
    "    \n",
    "    print(\"\\n--- TASK 1: EDA AND DATA CLEANING ---\")\n",
    "\n",
    "    # Drop duplicates\n",
    "    initial_rows = len(df)\n",
    "    df.drop_duplicates(subset=['Client_ID', 'date_time', 'process_step'], keep='first', inplace=True)\n",
    "\n",
    "    # Convert date_time and create Date column\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "    df['Date'] = df['date_time'].dt.date\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    # Create 'TestGroup' column\n",
    "    df['TestGroup'] = np.where(df['Variation'] == 'Control', 'Control', 'Test')\n",
    "    \n",
    "    print(f\"Total rows before cleaning: {initial_rows}\")\n",
    "    print(f\"Total rows after cleaning: {len(df)}\")\n",
    "    print(f\"Total unique clients after cleaning: {df['Client_ID'].nunique()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# --- 2. Client Behavior Analysis (Task 2: Analysis) ---\n",
    "def analyze_client_behavior(df):\n",
    "    \"\"\"Answers questions about client demographics and overall funnel performance.\"\"\"\n",
    "    if df is None: return None\n",
    "    \n",
    "    print(\"\\n--- TASK 2: CLIENT BEHAVIOR ANALYSIS ---\")\n",
    "    \n",
    "    # Filter clients with complete demographic data and create a copy\n",
    "    df_unique_clients = df.drop_duplicates(subset=['Client_ID'])\n",
    "    df_analysis_clients = df_unique_clients[df_unique_clients['clnt_age'].notnull()].copy() \n",
    "    total_clients = df_analysis_clients['Client_ID'].nunique()\n",
    "\n",
    "    # --- 3.1.1 Gender Analysis (Uses 'gendr') ---\n",
    "    gender_analysis = df_analysis_clients.groupby('gendr')['Client_ID'].count().sort_values(ascending=False)\n",
    "    gender_pct = (gender_analysis / total_clients * 100).round(2) \n",
    "    print(\"\\n3.1.1 Primary Clients by Gender:\")\n",
    "    print(gender_pct.to_frame(name='Client Pct (%)').to_string()) \n",
    "\n",
    "    # --- 3.1.2 Age Group Analysis (Uses 'clnt_age') ---\n",
    "    age_bins = [18, 30, 45, 60, 100]\n",
    "    age_labels = ['18-29 (Young)', '30-44 (Middle)', '45-59 (Senior)', '60+ (Retired)']\n",
    "    df_analysis_clients['Age_Group'] = pd.cut(df_analysis_clients['clnt_age'], bins=age_bins, labels=age_labels, right=False, include_lowest=True)\n",
    "    \n",
    "    # Corrected for FutureWarning: Added observed=True\n",
    "    age_analysis = df_analysis_clients.groupby('Age_Group', observed=True)['Client_ID'].count()\n",
    "    age_pct = (age_analysis / total_clients * 100).round(2)\n",
    "    print(\"\\n3.1.2 Primary Clients by Age Group:\")\n",
    "    print(age_pct.to_frame(name='Client Pct (%)').to_string())\n",
    "\n",
    "    # --- 3.2.1 Tenure Group Analysis (Uses 'clnt_tenure_yr') ---\n",
    "    tenure_bins = [0, 5, 10, 20, 50]\n",
    "    tenure_labels = ['<5 (New)', '5-9 (Mid-Term)', '10-19 (Long-Term)', '20+ (Veteran)']\n",
    "    df_analysis_clients['Tenure_Group'] = pd.cut(df_analysis_clients['clnt_tenure_yr'], bins=tenure_bins, labels=tenure_labels, right=False, include_lowest=True)\n",
    "    \n",
    "    # Corrected for FutureWarning: Added observed=True\n",
    "    tenure_analysis = df_analysis_clients.groupby('Tenure_Group', observed=True)['Client_ID'].count()\n",
    "    \n",
    "    # Corrected percentage calculation \n",
    "    tenure_pct = tenure_analysis.div(total_clients).mul(100).round(2)\n",
    "    \n",
    "    print(\"\\n3.2.1 Primary Clients by Tenure Group (Years Active):\")\n",
    "    print(tenure_pct.to_frame(name='Client Pct (%)').to_string())\n",
    "    \n",
    "    # --- 3.3.1 Overall Funnel Performance (Conversion Rate) ---\n",
    "    print(\"\\n3.3.1 Overall Process Funnel Analysis:\")\n",
    "    \n",
    "    process_steps = ['start', 'step_1', 'step_2', 'step_3', 'confirm']\n",
    "    step_activity = {step: df[df['process_step'] == step]['Client_ID'].nunique() for step in process_steps}\n",
    "    step_activity_series = pd.Series(step_activity).sort_index()\n",
    "\n",
    "    start_clients = step_activity.get('start', 0)\n",
    "    confirm_clients = step_activity.get('confirm', 0)\n",
    "    \n",
    "    # Final fix for rate calculation\n",
    "    if start_clients > 0:\n",
    "        completion_rate = round((confirm_clients / start_clients * 100), 2)\n",
    "    else:\n",
    "        completion_rate = 0\n",
    "\n",
    "    print(\"Clients reaching each step of the process:\")\n",
    "    print(step_activity_series.to_frame(name='Unique Clients').to_string())\n",
    "    print(f\"\\nOverall Process Completion Rate (Confirm/Start): {completion_rate}%\")\n",
    "    \n",
    "\n",
    "\n",
    "# --- Main Execution Block (Corrected Function Name) ---\n",
    "if __name__ == '__main__':\n",
    "    df_merged = load_and_merge_data(FILE_DEMO, FILE_WEB_1, FILE_WEB_2, FILE_EXPERIMENT)\n",
    "    \n",
    "    if df_merged is not None:\n",
    "        # FIX: Ensure function name is correct: perform_eda_and_cleaning\n",
    "        df_cleaned = perform_eda_and_cleaning(df_merged) \n",
    "        \n",
    "        if df_cleaned is not None:\n",
    "            analyze_client_behavior(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c797306c-8e68-4ad1-9181-a056e56df79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TASK 1: DATA LOADING AND MERGING ---\n",
      "All datasets merged successfully.\n",
      "\n",
      "--- TASK 1: EDA AND DATA CLEANING ---\n",
      "Total rows before cleaning: 449831\n",
      "Total rows after cleaning: 443896\n",
      "Total unique clients after cleaning: 70609\n",
      "\n",
      "--- TASK 2: CLIENT BEHAVIOR ANALYSIS ---\n",
      "\n",
      "3.1.1 Primary Clients by Gender:\n",
      "       Client Pct (%)\n",
      "gendr                \n",
      "U               34.17\n",
      "M               33.61\n",
      "F               32.22\n",
      "X                0.00\n",
      "\n",
      "3.1.2 Primary Clients by Age Group:\n",
      "                Client Pct (%)\n",
      "Age_Group                     \n",
      "18-29 (Young)            18.31\n",
      "30-44 (Middle)           27.03\n",
      "45-59 (Senior)           31.16\n",
      "60+ (Retired)            22.98\n",
      "\n",
      "3.2.1 Primary Clients by Tenure Group (Years Active):\n",
      "                   Client Pct (%)\n",
      "Tenure_Group                     \n",
      "<5 (New)                     7.39\n",
      "5-9 (Mid-Term)              37.40\n",
      "10-19 (Long-Term)           39.08\n",
      "20+ (Veteran)               16.09\n",
      "\n",
      "3.3.1 Overall Process Funnel Analysis:\n",
      "Clients reaching each step of the process:\n",
      "         Unique Clients\n",
      "confirm           47800\n",
      "start             70014\n",
      "step_1            62153\n",
      "step_2            57218\n",
      "step_3            53613\n",
      "\n",
      "Overall Process Completion Rate (Confirm/Start): 68.27%\n",
      "\n",
      "--- DISPLAYING FIRST 5 ROWS OF THE CLEANED TABLE (df_cleaned) ---\n",
      "   Client_ID Variation  clnt_tenure_yr  clnt_tenure_mnth  clnt_age gendr  num_accts        bal  calls_6_mnth  logons_6_mnth            visitor_id                      visit_id process_step           date_time       Date TestGroup\n",
      "0    9988021      Test             5.0              64.0      79.0     U        2.0  189023.86           1.0            4.0  580560515_7732621733  781255054_21935453173_531117       step_3 2017-04-17 15:27:07 2017-04-17      Test\n",
      "1    9988021      Test             5.0              64.0      79.0     U        2.0  189023.86           1.0            4.0  580560515_7732621733  781255054_21935453173_531117       step_2 2017-04-17 15:26:51 2017-04-17      Test\n",
      "2    9988021      Test             5.0              64.0      79.0     U        2.0  189023.86           1.0            4.0  580560515_7732621733  781255054_21935453173_531117       step_3 2017-04-17 15:19:22 2017-04-17      Test\n",
      "3    9988021      Test             5.0              64.0      79.0     U        2.0  189023.86           1.0            4.0  580560515_7732621733  781255054_21935453173_531117       step_2 2017-04-17 15:19:13 2017-04-17      Test\n",
      "4    9988021      Test             5.0              64.0      79.0     U        2.0  189023.86           1.0            4.0  580560515_7732621733  781255054_21935453173_531117       step_3 2017-04-17 15:18:04 2017-04-17      Test\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "# Silence SettingWithCopyWarning for categorical assignments\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "# --- Define File Names (Assuming these files are in the same directory) ---\n",
    "FILE_DEMO = 'df_final_demo.txt'\n",
    "FILE_WEB_1 = 'df_final_web_data_pt_1.txt'\n",
    "FILE_WEB_2 = 'df_final_web_data_pt_2.txt'\n",
    "FILE_EXPERIMENT = 'df_final_experiment_clients.txt'\n",
    "\n",
    "# --- 1. Data Loading and Merging (Task 1: Data Preparation) ---\n",
    "def load_and_merge_data(demo_file, web_1_file, web_2_file, experiment_file):\n",
    "    \"\"\"Loads and merges all required datasets.\"\"\"\n",
    "    print(\"--- TASK 1: DATA LOADING AND MERGING ---\")\n",
    "    try:\n",
    "        # Load datasets (using read_csv because your .txt files are CSV-formatted)\n",
    "        df_demo = pd.read_csv(demo_file)\n",
    "        df_web_1 = pd.read_csv(web_1_file)\n",
    "        df_web_2 = pd.read_csv(web_2_file)\n",
    "        df_experiment = pd.read_csv(experiment_file)\n",
    "\n",
    "        df_web = pd.concat([df_web_1, df_web_2], ignore_index=True)\n",
    "\n",
    "        # Standardize client ID column name\n",
    "        for df_ in [df_experiment, df_demo, df_web]:\n",
    "            if 'client_id' in df_.columns:\n",
    "                df_.rename(columns={'client_id': 'Client_ID'}, inplace=True)\n",
    "        \n",
    "        # Merge all data\n",
    "        df_merged = df_experiment.merge(df_demo, on='Client_ID', how='left')\n",
    "        df_merged = df_merged.merge(df_web, on='Client_ID', how='left')\n",
    "        print(\"All datasets merged successfully.\")\n",
    "        return df_merged\n",
    "    except Exception as e:\n",
    "        print(f\"Error during loading/merging: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- 1. EDA & Data Cleaning (Task 1: Data Preparation) ---\n",
    "def perform_eda_and_cleaning(df):\n",
    "    \"\"\"Performs initial EDA and cleaning steps.\"\"\"\n",
    "    if df is None: return None\n",
    "    \n",
    "    print(\"\\n--- TASK 1: EDA AND DATA CLEANING ---\")\n",
    "\n",
    "    # Drop duplicates\n",
    "    initial_rows = len(df)\n",
    "    df.drop_duplicates(subset=['Client_ID', 'date_time', 'process_step'], keep='first', inplace=True)\n",
    "\n",
    "    # Convert date_time and create Date column\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "    df['Date'] = df['date_time'].dt.date\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    # Create 'TestGroup' column\n",
    "    df['TestGroup'] = np.where(df['Variation'] == 'Control', 'Control', 'Test')\n",
    "    \n",
    "    print(f\"Total rows before cleaning: {initial_rows}\")\n",
    "    print(f\"Total rows after cleaning: {len(df)}\")\n",
    "    print(f\"Total unique clients after cleaning: {df['Client_ID'].nunique()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# --- 2. Client Behavior Analysis (Task 2: Analysis) ---\n",
    "def analyze_client_behavior(df):\n",
    "    \"\"\"Answers questions about client demographics and overall funnel performance.\"\"\"\n",
    "    if df is None: return None\n",
    "    \n",
    "    print(\"\\n--- TASK 2: CLIENT BEHAVIOR ANALYSIS ---\")\n",
    "    \n",
    "    # Filter clients with complete demographic data and create a copy\n",
    "    df_unique_clients = df.drop_duplicates(subset=['Client_ID'])\n",
    "    df_analysis_clients = df_unique_clients[df_unique_clients['clnt_age'].notnull()].copy() \n",
    "    total_clients = df_analysis_clients['Client_ID'].nunique()\n",
    "\n",
    "    # --- 3.1.1 Gender Analysis (Uses 'gendr') ---\n",
    "    gender_analysis = df_analysis_clients.groupby('gendr')['Client_ID'].count().sort_values(ascending=False)\n",
    "    gender_pct = (gender_analysis / total_clients * 100).round(2) \n",
    "    print(\"\\n3.1.1 Primary Clients by Gender:\")\n",
    "    print(gender_pct.to_frame(name='Client Pct (%)').to_string()) \n",
    "\n",
    "    # --- 3.1.2 Age Group Analysis (Uses 'clnt_age') ---\n",
    "    age_bins = [18, 30, 45, 60, 100]\n",
    "    age_labels = ['18-29 (Young)', '30-44 (Middle)', '45-59 (Senior)', '60+ (Retired)']\n",
    "    df_analysis_clients['Age_Group'] = pd.cut(df_analysis_clients['clnt_age'], bins=age_bins, labels=age_labels, right=False, include_lowest=True)\n",
    "    \n",
    "    # Corrected for FutureWarning: Added observed=True\n",
    "    age_analysis = df_analysis_clients.groupby('Age_Group', observed=True)['Client_ID'].count()\n",
    "    age_pct = (age_analysis / total_clients * 100).round(2)\n",
    "    print(\"\\n3.1.2 Primary Clients by Age Group:\")\n",
    "    print(age_pct.to_frame(name='Client Pct (%)').to_string())\n",
    "\n",
    "    # --- 3.2.1 Tenure Group Analysis (Uses 'clnt_tenure_yr') ---\n",
    "    tenure_bins = [0, 5, 10, 20, 50]\n",
    "    tenure_labels = ['<5 (New)', '5-9 (Mid-Term)', '10-19 (Long-Term)', '20+ (Veteran)']\n",
    "    df_analysis_clients['Tenure_Group'] = pd.cut(df_analysis_clients['clnt_tenure_yr'], bins=tenure_bins, labels=tenure_labels, right=False, include_lowest=True)\n",
    "    \n",
    "    # Corrected for FutureWarning: Added observed=True\n",
    "    tenure_analysis = df_analysis_clients.groupby('Tenure_Group', observed=True)['Client_ID'].count()\n",
    "    \n",
    "    # Corrected percentage calculation \n",
    "    tenure_pct = tenure_analysis.div(total_clients).mul(100).round(2)\n",
    "    \n",
    "    print(\"\\n3.2.1 Primary Clients by Tenure Group (Years Active):\")\n",
    "    print(tenure_pct.to_frame(name='Client Pct (%)').to_string())\n",
    "    \n",
    "    # --- 3.3.1 Overall Funnel Performance (Conversion Rate) ---\n",
    "    print(\"\\n3.3.1 Overall Process Funnel Analysis:\")\n",
    "    \n",
    "    process_steps = ['start', 'step_1', 'step_2', 'step_3', 'confirm']\n",
    "    step_activity = {step: df[df['process_step'] == step]['Client_ID'].nunique() for step in process_steps}\n",
    "    step_activity_series = pd.Series(step_activity).sort_index()\n",
    "\n",
    "    start_clients = step_activity.get('start', 0)\n",
    "    confirm_clients = step_activity.get('confirm', 0)\n",
    "    \n",
    "    if start_clients > 0:\n",
    "        completion_rate = round((confirm_clients / start_clients * 100), 2)\n",
    "    else:\n",
    "        completion_rate = 0\n",
    "\n",
    "    print(\"Clients reaching each step of the process:\")\n",
    "    print(step_activity_series.to_frame(name='Unique Clients').to_string())\n",
    "    print(f\"\\nOverall Process Completion Rate (Confirm/Start): {completion_rate}%\")\n",
    "    \n",
    "\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "if __name__ == '__main__':\n",
    "    df_merged = load_and_merge_data(FILE_DEMO, FILE_WEB_1, FILE_WEB_2, FILE_EXPERIMENT)\n",
    "    \n",
    "    if df_merged is not None:\n",
    "        df_cleaned = perform_eda_and_cleaning(df_merged) \n",
    "        \n",
    "        if df_cleaned is not None:\n",
    "            analyze_client_behavior(df_cleaned)\n",
    "            \n",
    "            # --- DISPLAY THE CLEANED TABLE ---\n",
    "            print(\"\\n--- DISPLAYING FIRST 5 ROWS OF THE CLEANED TABLE (df_cleaned) ---\")\n",
    "            print(df_cleaned.head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad7d1e7-5ceb-49fa-8c7b-886b5f793c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e552683-9db2-4fe0-b20a-f04d24401eab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
